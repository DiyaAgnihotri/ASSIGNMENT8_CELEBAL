# -*- coding: utf-8 -*-
"""app8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13tp4wWd-6r7omh6HLL1OSPR2MGJr681B
"""

import streamlit as st
import pandas as pd
import numpy as np
from assignment8_celebal import OptimizedLoanPipeline
import os
import time

# Page config MUST come first
st.set_page_config(
    page_title="üè¶ Loan Eligibility + AI Chatbot",
    layout="centered",
    initial_sidebar_state="collapsed"
)

def set_background():
    st.markdown("""
        <style>
        .stApp {
            background-image: url('https://images.unsplash.com/photo-1724304406928-c43b01912fa1?fm=jpg&q=60&w=3000&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxzZWFyY2h8M3x8bG9hbnxlbnwwfHwwfHx8MA%3D%3D');
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        .main-container {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            padding: 2rem;
            border-radius: 20px;
            box-shadow: 0 15px 35px rgba(0,0,0,0.1);
            margin: 20px auto;
            border: 1px solid rgba(255,255,255,0.2);
        }

        .title-container {
            text-align: center;
            margin-bottom: 2rem;
        }

        .title-container h1 {
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 700;
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }

        .subtitle {
            color: #666;
            font-size: 1.1rem;
            margin-bottom: 1rem;
        }

        .stButton button {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            font-weight: 600;
            border: none;
            border-radius: 12px;
            padding: 0.7rem 2rem;
            font-size: 16px;
            transition: all 0.3s ease;
            width: 100%;
        }

        .stButton button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4);
        }

        .stTabs [data-baseweb="tab-list"] {
            gap: 20px;
            justify-content: center;
            margin-bottom: 2rem;
        }

        .stTabs [data-baseweb="tab"] {
            background: rgba(102, 126, 234, 0.1);
            border-radius: 10px;
            padding: 12px 24px;
            font-weight: 600;
        }

        .prediction-result {
            background: linear-gradient(135deg, #4CAF50, #45a049);
            color: white;
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            font-size: 1.2rem;
            font-weight: 600;
            margin: 1rem 0;
            box-shadow: 0 5px 15px rgba(76, 175, 80, 0.3);
        }

        .prediction-result.rejected {
            background: linear-gradient(135deg, #f44336, #d32f2f);
            box-shadow: 0 5px 15px rgba(244, 67, 54, 0.3);
        }

        .answer-box {
            background: linear-gradient(135deg, #2c3e50, #34495e);
            color: white;
            padding: 1.5rem;
            border-radius: 15px;
            margin-top: 1rem;
            font-size: 16px;
            line-height: 1.7;
            box-shadow: 0 5px 15px rgba(44, 62, 80, 0.3);
        }

        .info-box {
            background: linear-gradient(135deg, #17a2b8, #138496);
            color: white;
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
            font-size: 14px;
        }

        .warning-box {
            background: linear-gradient(135deg, #ffc107, #e0a800);
            color: #212529;
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
            font-size: 14px;
        }

        .stats-container {
            background: rgba(102, 126, 234, 0.1);
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
        }

        .loading-container {
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 2rem;
        }

        .form-section {
            background: rgba(248, 249, 250, 0.8);
            padding: 1.5rem;
            border-radius: 15px;
            margin-bottom: 1rem;
        }

        .metric-card {
            background: white;
            padding: 1rem;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin: 0.5rem 0;
        }

        .footer {
            text-align: center;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 2px solid rgba(102, 126, 234, 0.2);
            color: #666;
            font-size: 16px;
        }

        .status-badge {
            display: inline-block;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-weight: 600;
            margin: 0.2rem;
        }

        .status-ready {
            background: #d4edda;
            color: #155724;
        }

        .status-loading {
            background: #fff3cd;
            color: #856404;
        }

        .status-compressed {
            background: #d1ecf1;
            color: #0c5460;
        }

        .file-size-info {
            background: rgba(0, 123, 255, 0.1);
            border-left: 4px solid #007bff;
            padding: 1rem;
            margin: 1rem 0;
            border-radius: 5px;
        }
        </style>
    """, unsafe_allow_html=True)

def check_file_sizes():
    """Check and display file sizes"""
    file_info = {}

    files_to_check = [
        ('loan_model.pkl', 'ML Model'),
        ('rag_cache.pkl', 'Old RAG Cache'),
        ('rag_cache_compressed.gz', 'Compressed RAG Cache'),
        ('Training Dataset.csv', 'Training Data'),
        ('Test Dataset.csv', 'Test Data')
    ]

    for filename, description in files_to_check:
        if os.path.exists(filename):
            size_mb = os.path.getsize(filename) / (1024 * 1024)
            file_info[description] = {
                'size': size_mb,
                'exists': True,
                'filename': filename
            }
        else:
            file_info[description] = {
                'size': 0,
                'exists': False,
                'filename': filename
            }

    return file_info

# Initialize session state for caching
@st.cache_resource
def load_pipeline():
    """Load and cache the pipeline with compressed RAG support"""

    file_info = check_file_sizes()

    # Display loading info
    info_placeholder = st.empty()

    with info_placeholder.container():
        st.markdown("""
        <div class="info-box">
            üöÄ <strong>Loading AI Models...</strong><br>
            Using optimized compressed storage for faster GitHub deployment
        </div>
        """, unsafe_allow_html=True)

    with st.spinner("ü§ñ Initializing AI system..."):
        pipeline = OptimizedLoanPipeline()

        # Check if model exists
        if os.path.exists('loan_model.pkl'):
            st.info("üìÇ Loading ML model from saved file...")
            pipeline.load_model('loan_model.pkl')

            # Load training data for RAG
            X_train, y_train, df_raw = pipeline.load_and_preprocess_train()

            # Try to load compressed RAG cache first, then fallback to regular
            if os.path.exists('rag_cache_compressed.gz'):
                st.info("üì¶ Loading compressed RAG cache (optimized for GitHub)...")
                pipeline.prepare_rag_optimized(df_raw, cache_file='rag_cache_compressed.gz')
                cache_type = "Compressed"
            elif os.path.exists('rag_cache.pkl'):
                st.info("üìÇ Loading regular RAG cache...")
                pipeline.prepare_rag_optimized(df_raw, cache_file='rag_cache.pkl')
                cache_type = "Regular"
            else:
                st.info("üîÑ Building new compressed RAG cache...")
                pipeline.prepare_rag_optimized(df_raw, cache_file='rag_cache_compressed.gz')
                cache_type = "New Compressed"

        else:
            st.info("üîÑ Training new model... This will take a few minutes.")

            # Train new model
            X_train, y_train, df_raw = pipeline.load_and_preprocess_train()
            X_test, loan_ids = pipeline.load_and_preprocess_test()

            # Train and save
            pipeline.train_and_predict(X_train, y_train, X_test)

            # Create compressed RAG cache by default
            pipeline.prepare_rag_optimized(df_raw, cache_file='rag_cache_compressed.gz')
            pipeline.save_model()
            cache_type = "New Compressed"

        # Clear info and show success
        info_placeholder.empty()

        # Show file size information
        updated_file_info = check_file_sizes()

        success_msg = f"‚úÖ AI models loaded successfully! Using {cache_type} RAG cache."

        if updated_file_info['Compressed RAG Cache']['exists']:
            cache_size = updated_file_info['Compressed RAG Cache']['size']
            success_msg += f" Cache size: {cache_size:.1f}MB"

            if cache_size < 25:  # GitHub friendly size
                success_msg += " üéâ (GitHub friendly!)"

        st.success(success_msg)
        return pipeline

def predict_single_loan(pipeline, input_data):
    """Make prediction for a single loan application"""
    try:
        # Convert input to DataFrame
        input_df = pd.DataFrame([input_data])

        # Make prediction
        prediction = pipeline.model.predict(input_df)[0]
        probability = pipeline.model.predict_proba(input_df)[0]

        return {
            'prediction': int(prediction),
            'probability': float(max(probability)),
            'approval_prob': float(probability[1]) if len(probability) > 1 else 0.0
        }
    except Exception as e:
        st.error(f"‚ùå Prediction error: {str(e)}")
        return None

def display_system_info():
    """Display system and file information"""
    file_info = check_file_sizes()

    st.markdown("### üíæ System Information")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**üìÅ File Status:**")
        for description, info in file_info.items():
            if info['exists']:
                size_str = f"{info['size']:.1f}MB" if info['size'] > 0 else "< 0.1MB"
                status_icon = "‚úÖ" if info['size'] < 25 else "‚ö†Ô∏è" if info['size'] < 100 else "‚ùå"
                st.text(f"{status_icon} {description}: {size_str}")
            else:
                st.text(f"‚ùå {description}: Not found")

    with col2:
        st.markdown("**üöÄ Optimization Features:**")
        features = [
            "‚úÖ Compressed RAG cache (.gz format)",
            "‚úÖ Smart data sampling (500 samples)",
            "‚úÖ Float16 embeddings for size reduction",
            "‚úÖ Gzip compression (level 9)",
            "‚úÖ GitHub LFS compatible",
            "‚úÖ Auto-fallback to regular cache"
        ]
        for feature in features:
            st.text(feature)

    # Show recommendations
    compressed_exists = file_info['Compressed RAG Cache']['exists']
    old_cache_exists = file_info['Old RAG Cache']['exists']

    if old_cache_exists and not compressed_exists:
        st.markdown("""
        <div class="warning-box">
            ‚ö†Ô∏è <strong>Recommendation:</strong> You have an old RAG cache file.
            The system will automatically create a compressed version for better GitHub compatibility.
        </div>
        """, unsafe_allow_html=True)

    elif compressed_exists:
        cache_size = file_info['Compressed RAG Cache']['size']
        if cache_size > 25:
            st.markdown("""
            <div class="warning-box">
                ‚ö†Ô∏è <strong>GitHub Size Warning:</strong> Your cache file is larger than 25MB.
                Consider using Git LFS or further reducing the sample size.
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="info-box">
                ‚úÖ <strong>GitHub Ready:</strong> Your compressed cache is under 25MB and GitHub friendly!
            </div>
            """, unsafe_allow_html=True)

def main():
    set_background()

    # Load pipeline (cached)
    pipeline = load_pipeline()

    # Main container
    with st.container():
        st.markdown('<div class="main-container">', unsafe_allow_html=True)

        # Title section
        st.markdown("""
        <div class="title-container">
            <h1>üè¶ Smart Loan Predictor</h1>
            <p class="subtitle">AI-powered loan eligibility prediction with intelligent Q&A chatbot</p>
        </div>
        """, unsafe_allow_html=True)

        # Status indicator
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown('<div class="status-badge status-ready">ü§ñ AI Model Ready</div>', unsafe_allow_html=True)
        with col2:
            st.markdown('<div class="status-badge status-ready">üí¨ Chatbot Online</div>', unsafe_allow_html=True)
        with col3:
            compressed_cache_exists = os.path.exists('rag_cache_compressed.gz')
            if compressed_cache_exists:
                st.markdown('<div class="status-badge status-compressed">üì¶ Compressed Cache</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="status-badge status-ready">‚ö° Fast Predictions</div>', unsafe_allow_html=True)

        # Main tabs
        tab1, tab2, tab3, tab4 = st.tabs(["üéØ Loan Prediction", "üí¨ AI Assistant", "üìä Model Info", "‚öôÔ∏è System Info"])

        with tab1:
            st.markdown("### üìù Enter Loan Application Details")

            # Form in columns for better layout
            col1, col2 = st.columns(2)

            with col1:
                st.markdown('<div class="form-section">', unsafe_allow_html=True)
                st.markdown("**üë§ Personal Information**")
                gender = st.selectbox("Gender", ["Male", "Female"], key="gender")
                married = st.selectbox("Marital Status", ["No", "Yes"], key="married")
                dependents = st.selectbox("Number of Dependents", ["0", "1", "2", "3"], key="dependents")
                education = st.selectbox("Education Level", ["Graduate", "Not Graduate"], key="education")
                self_employed = st.selectbox("Self Employed", ["No", "Yes"], key="self_employed")
                st.markdown('</div>', unsafe_allow_html=True)

            with col2:
                st.markdown('<div class="form-section">', unsafe_allow_html=True)
                st.markdown("**üí∞ Financial Information**")
                applicant_income = st.number_input(
                    "Applicant Income (‚Çπ)",
                    min_value=0,
                    value=5000,
                    step=1000,
                    key="app_income"
                )
                coapplicant_income = st.number_input(
                    "Co-applicant Income (‚Çπ)",
                    min_value=0,
                    value=0,
                    step=1000,
                    key="coapp_income"
                )
                loan_amount = st.number_input(
                    "Loan Amount (‚Çπ)",
                    min_value=0,
                    value=100000,
                    step=10000,
                    key="loan_amt"
                )
                loan_term = st.number_input(
                    "Loan Term (months)",
                    min_value=12,
                    value=360,
                    step=12,
                    key="loan_term"
                )
                credit_history = st.selectbox(
                    "Credit History",
                    [1.0, 0.0],
                    format_func=lambda x: "Good" if x == 1.0 else "Poor",
                    key="credit"
                )
                property_area = st.selectbox(
                    "Property Area",
                    ["Urban", "Rural", "Semiurban"],
                    key="property"
                )
                st.markdown('</div>', unsafe_allow_html=True)

            # Prediction button
            st.markdown("<br>", unsafe_allow_html=True)
            if st.button("üîÆ Predict Loan Eligibility", key="predict_btn"):
                with st.spinner("ü§î Analyzing your application..."):
                    # Encode input data using pipeline's encoders
                    input_data = {
                        "Gender": 0 if gender == "Male" else 1,
                        "Married": 0 if married == "No" else 1,
                        "Dependents": int(dependents),
                        "Education": 0 if education == "Graduate" else 1,
                        "Self_Employed": 0 if self_employed == "No" else 1,
                        "ApplicantIncome": applicant_income,
                        "CoapplicantIncome": coapplicant_income,
                        "LoanAmount": loan_amount,
                        "Loan_Amount_Term": loan_term,
                        "Credit_History": credit_history,
                        "Property_Area": {"Urban": 2, "Rural": 0, "Semiurban": 1}[property_area]
                    }

                    result = predict_single_loan(pipeline, input_data)

                    if result:
                        if result['prediction'] == 1:
                            st.markdown(f"""
                            <div class="prediction-result">
                                ‚úÖ <strong>LOAN APPROVED!</strong><br>
                                Approval Confidence: {result['approval_prob']:.1%}
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.markdown(f"""
                            <div class="prediction-result rejected">
                                ‚ùå <strong>LOAN REJECTED</strong><br>
                                Approval Probability: {result['approval_prob']:.1%}
                            </div>
                            """, unsafe_allow_html=True)

                        # Additional insights
                        st.markdown("### üí° Quick Insights")
                        col1, col2, col3 = st.columns(3)

                        with col1:
                            total_income = applicant_income + coapplicant_income
                            st.metric("Total Income", f"‚Çπ{total_income:,}")

                        with col2:
                            if loan_amount > 0:
                                income_ratio = total_income / loan_amount * 100
                                st.metric("Income to Loan Ratio", f"{income_ratio:.1f}%")

                        with col3:
                            credit_status = "Excellent" if credit_history == 1.0 else "Needs Improvement"
                            st.metric("Credit Status", credit_status)

        with tab2:
            st.markdown("### üí¨ Ask the AI Assistant")
            st.markdown("Ask any question about loan approvals, trends, or get personalized advice!")

            # Display RAG info
            if hasattr(pipeline, 'rag_embeddings') and pipeline.rag_embeddings is not None:
                n_samples = len(pipeline.rag_embeddings)
                st.markdown(f"""
                <div class="info-box">
                    üß† <strong>AI Knowledge Base:</strong> {n_samples} training examples available for intelligent responses
                </div>
                """, unsafe_allow_html=True)

            # Sample questions
            st.markdown("**üí° Try these sample questions:**")
            sample_questions = [
                "What factors increase loan approval chances?",
                "Are married applicants more likely to get approved?",
                "How does education level affect loan approval?",
                "What's the average approval rate for self-employed applicants?",
                "Do urban applicants have better approval rates?"
            ]

            selected_sample = st.selectbox("Choose a sample question:", [""] + sample_questions)

            user_question = st.text_area(
                "Your Question:",
                value=selected_sample if selected_sample else "",
                placeholder="E.g., Are self-employed applicants more likely to get rejected?",
                height=100
            )

            col1, col2 = st.columns([3, 1])
            with col1:
                ask_btn = st.button("üß† Get AI Answer", key="ask_btn")
            with col2:
                if st.button("üîÑ Clear", key="clear_btn"):
                    st.rerun()

            if ask_btn and user_question.strip():
                with st.spinner("ü§ñ AI is thinking..."):
                    start_time = time.time()
                    response = pipeline.answer_query_optimized(user_question)
                    end_time = time.time()

                    # Format response with line breaks
                    formatted_response = response.replace('\n', '<br>')

                    st.markdown(f"""
                    <div class="answer-box">
                        <strong>ü§ñ AI Assistant:</strong><br><br>
                        {formatted_response}
                        <br><br>
                        <small>‚ö° Answered in {end_time - start_time:.2f} seconds</small>
                    </div>
                    """, unsafe_allow_html=True)

            elif ask_btn:
                st.warning("‚ö†Ô∏è Please enter a question to get started!")

        with tab3:
            st.markdown("### üìä Model Performance & Information")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("""
                <div class="metric-card">
                    <h4>ü§ñ Model Details</h4>
                    <ul>
                        <li><strong>Algorithm:</strong> XGBoost Classifier</li>
                        <li><strong>Features:</strong> 11 key factors</li>
                        <li><strong>Training:</strong> Optimized for speed</li>
                        <li><strong>RAG System:</strong> Semantic search enabled</li>
                        <li><strong>Storage:</strong> Compressed cache</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)

            with col2:
                st.markdown("""
                <div class="metric-card">
                    <h4>‚ö° Performance</h4>
                    <ul>
                        <li><strong>Prediction Speed:</strong> < 1 second</li>
                        <li><strong>RAG Response:</strong> < 2 seconds</li>
                        <li><strong>Cache System:</strong> Compressed enabled</li>
                        <li><strong>Model Size:</strong> GitHub optimized</li>
                        <li><strong>Embedding Format:</strong> Float16</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)

            if hasattr(pipeline.model, 'feature_importances_'):
                st.markdown("### üìà Feature Importance")
                feature_names = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',
                               'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',
                               'Loan_Amount_Term', 'Credit_History', 'Property_Area']

                importance_df = pd.DataFrame({
                    'Feature': feature_names,
                    'Importance': pipeline.model.feature_importances_
                }).sort_values('Importance', ascending=True)

                st.bar_chart(importance_df.set_index('Feature'))

        with tab4:
            display_system_info()

            # Optimization controls
            st.markdown("### üõ†Ô∏è Optimization Tools")

            col1, col2 = st.columns(2)

            with col1:
                if st.button("üì¶ Create Compressed Cache", key="compress_btn"):
                    with st.spinner("Creating compressed RAG cache..."):
                        try:
                            # Load data and create compressed cache
                            X_train, y_train, df_raw = pipeline.load_and_preprocess_train()
                            pipeline.prepare_rag_minimal(df_raw, max_samples=500)
                            st.success("‚úÖ Compressed cache created successfully!")
                            st.rerun()
                        except Exception as e:
                            st.error(f"‚ùå Error creating cache: {str(e)}")

            with col2:
                if st.button("üßπ Clean Old Files", key="clean_btn"):
                    files_to_clean = ['rag_cache.pkl']  # Don't delete compressed version
                    cleaned = []

                    for file in files_to_clean:
                        if os.path.exists(file):
                            try:
                                os.remove(file)
                                cleaned.append(file)
                            except Exception as e:
                                st.error(f"Error removing {file}: {str(e)}")

                    if cleaned:
                        st.success(f"‚úÖ Cleaned files: {', '.join(cleaned)}")
                        st.rerun()
                    else:
                        st.info("‚ÑπÔ∏è No old files to clean")

            # GitHub deployment tips
            st.markdown("### üöÄ GitHub Deployment Tips")
            st.markdown("""
            <div class="file-size-info">
                <strong>üìã Deployment Checklist:</strong><br>
                ‚úÖ Use compressed RAG cache (.gz format)<br>
                ‚úÖ Keep cache files under 25MB for direct upload<br>
                ‚úÖ Use Git LFS for files 25MB-100MB<br>
                ‚úÖ Add large files to .gitignore if needed<br>
                ‚úÖ Test with minimal sample data first
            </div>
            """, unsafe_allow_html=True)

        # Footer
        st.markdown("""
        <div class="footer">
            <strong>üöÄ Built with Advanced AI & Machine Learning</strong><br>
            Made with ‚ù§Ô∏è by <strong>Diya Agnihotri</strong> | Powered by Streamlit & XGBoost<br>
            <small>Optimized for GitHub deployment with compressed storage</small>
        </div>
        """, unsafe_allow_html=True)

        st.markdown('</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()

